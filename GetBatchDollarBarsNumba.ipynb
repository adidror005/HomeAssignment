{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNZzGKlR4YI9eRcL9RiD2b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adidror005/HomeAssignment/blob/main/GetBatchDollarBarsNumba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz5j1EF2P2sZ",
        "outputId": "49ef0c39-5623-4a11-8299-6c2261d0b6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numba import njit\n",
        "from typing import List\n",
        "from dataclasses import dataclass\n",
        "import glob\n",
        "BARS_PER_DAY = 50\n",
        "\n",
        "# ================== Data Class for Dollar Bars ==================\n",
        "@dataclass\n",
        "class DollarBar:\n",
        "    ts_start: pd.Timestamp\n",
        "    ts_end: pd.Timestamp\n",
        "    open: float\n",
        "    high: float\n",
        "    low: float\n",
        "    close: float\n",
        "    volume: int\n",
        "    dollar_amount: float\n",
        "\n",
        "# ================== Dollar Bar Creation Logic ==================\n",
        "@njit\n",
        "def _create_dollar_bars(price, size, day_int, daily_dollar_amounts, period_len=28):\n",
        "    dollar_threshold = np.median(np.array(daily_dollar_amounts[-period_len:])) / BARS_PER_DAY\n",
        "    n = len(price)\n",
        "    max_bars = n\n",
        "    bar_indices = np.empty((max_bars, 2), dtype=np.int64)\n",
        "    opens = np.empty(max_bars)\n",
        "    highs = np.empty(max_bars)\n",
        "    lows = np.empty(max_bars)\n",
        "    closes = np.empty(max_bars)\n",
        "    volumes = np.empty(max_bars, dtype=np.int64)\n",
        "    dollar_amts = np.empty(max_bars)\n",
        "\n",
        "    count = 0\n",
        "    dollar_sum = 0.0\n",
        "    volume = 0\n",
        "    start_idx = 0\n",
        "    open_price = high = low = 0.0\n",
        "    prev_day = day_int[0]\n",
        "    new_daily_dollar_amount = 0.0\n",
        "\n",
        "    for i in range(n):\n",
        "        if day_int[i] != prev_day:\n",
        "            if i > start_idx:\n",
        "                bar_indices[count] = start_idx, i - 1\n",
        "                opens[count] = open_price\n",
        "                highs[count] = high\n",
        "                lows[count] = low\n",
        "                closes[count] = price[i - 1]\n",
        "                volumes[count] = volume\n",
        "                dollar_amts[count] = dollar_sum\n",
        "                count += 1\n",
        "\n",
        "                daily_dollar_amounts.append(new_daily_dollar_amount)\n",
        "                dollar_threshold = np.median(np.array(daily_dollar_amounts[-period_len:])) / BARS_PER_DAY\n",
        "                new_daily_dollar_amount = 0.0\n",
        "\n",
        "            dollar_sum = 0.0\n",
        "            volume = 0\n",
        "            start_idx = i\n",
        "            open_price = price[i]\n",
        "            high = price[i]\n",
        "            low = price[i]\n",
        "\n",
        "        high = max(high, price[i])\n",
        "        low = min(low, price[i])\n",
        "        volume += size[i]\n",
        "        trade_value = price[i] * size[i]\n",
        "        dollar_sum += trade_value\n",
        "        new_daily_dollar_amount += trade_value\n",
        "\n",
        "        if dollar_sum >= dollar_threshold:\n",
        "            bar_indices[count] = start_idx, i\n",
        "            opens[count] = open_price\n",
        "            highs[count] = high\n",
        "            lows[count] = low\n",
        "            closes[count] = price[i]\n",
        "            volumes[count] = volume\n",
        "            dollar_amts[count] = dollar_sum\n",
        "            count += 1\n",
        "            dollar_sum = 0.0\n",
        "            volume = 0\n",
        "\n",
        "\n",
        "        prev_day = day_int[i]\n",
        "\n",
        "    # Handle the last bar if not closed\n",
        "    if dollar_sum > 0 and start_idx < n:\n",
        "        bar_indices[count] = start_idx, n - 1\n",
        "        opens[count] = open_price\n",
        "        highs[count] = high\n",
        "        lows[count] = low\n",
        "        closes[count] = price[-1]\n",
        "        volumes[count] = volume\n",
        "        dollar_amts[count] = dollar_sum\n",
        "        daily_dollar_amounts.append(new_daily_dollar_amount)\n",
        "        count += 1\n",
        "\n",
        "    return bar_indices[:count], opens[:count], highs[:count], lows[:count], closes[:count], volumes[:count], dollar_amts[:count]\n",
        "\n",
        "# ================== Create Dollar Bars Fast ==================\n",
        "def create_dollar_bars_fast(df: pd.DataFrame, daily_dollar_amounts: List[float], period_len=28) -> List[DollarBar]:\n",
        "    price = df['price'].values\n",
        "    size = df['size'].values\n",
        "    day_int = df['day_int'].values\n",
        "    ts = df.index.values\n",
        "\n",
        "    bar_indices, opens, highs, lows, closes, volumes, dollar_amts = _create_dollar_bars(price, size, day_int, daily_dollar_amounts, period_len)\n",
        "\n",
        "    dollar_bars = [\n",
        "        DollarBar(pd.Timestamp(ts[start]), pd.Timestamp(ts[end]), opens[i], highs[i], lows[i], closes[i], volumes[i], dollar_amts[i])\n",
        "        for i, (start, end) in enumerate(bar_indices)\n",
        "    ]\n",
        "    return dollar_bars\n",
        "\n",
        "\n",
        "# ================== Main Processing Loop ==================\n",
        "symbol = 'AMD'\n",
        "files = sorted(glob.glob(f'/content/drive/MyDrive/stock_trades_daily/{symbol}/*.parquet'))\n",
        "span = 200\n",
        "alpha = 2 / (span + 1)\n",
        "ewms = np.empty(0, dtype=np.float64)\n",
        "dollar_bars = []\n",
        "daily_dollar_amounts = []\n",
        "for i, file in enumerate(files):\n",
        "    print(f\"Processing File: {file}\")\n",
        "    df = pd.read_parquet(file)\n",
        "\n",
        "    # === Reintroduced Your Filtering Logic ===\n",
        "    df = df.droplevel(0)\n",
        "    df['conditions'] = df.conditions.apply(lambda l: \"\".join(l))\n",
        "    df = df[df.conditions.isin(['@', '@F', '@I', '@FI'])]\n",
        "    df.index = df.index.tz_convert(\"US/Eastern\")\n",
        "    df = df.between_time('9:30', '16:00')\n",
        "\n",
        "    # Add necessary columns for processing\n",
        "    df['day'] = df.index.date\n",
        "    df['day_int'] = df['day'].astype('datetime64[s]').astype('int64')\n",
        "    df['dollar_amount'] = df['price'] * df['size']\n",
        "\n",
        "    # Initialize the first 28-day median with the first file's daily sum\n",
        "    if i == 0:\n",
        "        median_dollar_amount = np.median(df.groupby('day')['dollar_amount'].sum())\n",
        "        daily_dollar_amounts = [median_dollar_amount] * 28\n",
        "\n",
        "    # Create dollar bars\n",
        "    new_bars = create_dollar_bars_fast(df, daily_dollar_amounts)\n",
        "    dollar_bars.extend(new_bars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSBch0HCY1Kg",
        "outputId": "9d313eba-28c5-4669-84d2-da0003d2ae15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-01-02_2017-01-30.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-01-30_2017-02-27.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-02-27_2017-03-27.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-03-27_2017-04-24.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-04-24_2017-05-22.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-05-22_2017-06-19.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-06-19_2017-07-17.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-07-17_2017-08-14.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-08-14_2017-09-11.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-09-11_2017-10-09.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-10-09_2017-11-06.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-11-06_2017-12-04.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2017-12-04_2018-01-01.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-01-01_2018-01-29.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-01-29_2018-02-26.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-02-26_2018-03-26.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-03-26_2018-04-23.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-04-23_2018-05-21.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-05-21_2018-06-18.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-06-18_2018-07-16.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-07-16_2018-08-13.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-08-13_2018-09-10.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-09-10_2018-10-08.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-10-08_2018-11-05.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-11-05_2018-12-03.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-12-03_2018-12-31.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2018-12-31_2019-01-28.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-01-28_2019-02-25.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-02-25_2019-03-25.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-03-25_2019-04-22.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-04-22_2019-05-20.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-05-20_2019-06-17.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-06-17_2019-07-15.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-07-15_2019-08-12.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-08-12_2019-09-09.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-09-09_2019-10-07.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-10-07_2019-11-04.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-11-04_2019-12-02.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-12-02_2019-12-30.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2019-12-30_2020-01-27.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-01-27_2020-02-24.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-02-24_2020-03-23.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-03-23_2020-04-20.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-04-20_2020-05-18.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-05-18_2020-06-15.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-06-15_2020-07-13.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-07-13_2020-08-10.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-08-10_2020-09-07.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-09-07_2020-10-05.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-10-05_2020-11-02.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-11-02_2020-11-30.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-11-30_2020-12-28.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2020-12-28_2021-01-25.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-01-25_2021-02-22.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-02-22_2021-03-22.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-03-22_2021-04-19.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-04-19_2021-05-17.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-05-17_2021-06-14.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-80806288d636>:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day'] = df.index.date\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-06-14_2021-07-12.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-07-12_2021-08-09.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-08-09_2021-09-06.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-09-06_2021-10-04.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-10-04_2021-11-01.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-11-01_2021-11-29.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-11-29_2021-12-27.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2021-12-27_2022-01-24.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-80806288d636>:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day'] = df.index.date\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-01-24_2022-02-21.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-02-21_2022-03-21.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-03-21_2022-04-18.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-04-18_2022-05-16.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-05-16_2022-06-13.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-06-13_2022-07-11.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-07-11_2022-08-08.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-08-08_2022-09-05.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-09-05_2022-10-03.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-10-03_2022-10-31.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-10-31_2022-11-28.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-11-28_2022-12-26.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2022-12-26_2023-01-23.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-01-23_2023-02-20.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-02-20_2023-03-20.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-03-20_2023-04-17.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-04-17_2023-05-15.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-05-15_2023-06-12.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-06-12_2023-07-10.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-07-10_2023-08-07.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-08-07_2023-09-04.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-09-04_2023-10-02.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-10-02_2023-10-30.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-10-30_2023-11-27.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-11-27_2023-12-25.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2023-12-25_2024-01-22.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-01-22_2024-02-19.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-02-19_2024-03-18.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-03-18_2024-04-15.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-04-15_2024-05-13.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-05-13_2024-06-10.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-06-10_2024-07-08.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-07-08_2024-08-05.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-08-05_2024-09-02.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-09-02_2024-09-30.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-09-30_2024-10-28.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-10-28_2024-11-25.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-11-25_2024-12-23.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-80806288d636>:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day'] = df.index.date\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2024-12-23_2025-01-20.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2025-01-20_2025-02-17.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2025-02-17_2025-03-17.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2025-03-17_2025-04-14.parquet\n",
            "Processing File: /content/drive/MyDrive/stock_trades_daily/AMD/stock_trades_2025-04-14_2025-05-09_partial.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Dollar Bars and Daily Dollar Bar Amounts to Parquet"
      ],
      "metadata": {
        "id": "0BMTrCj0j1P6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ln8UjHcxRBt6"
      },
      "outputs": [],
      "source": [
        "df_dollar_bars=pd.DataFrame(dollar_bars)\n",
        "df_daily_dollar_amounts=pd.DataFrame(daily_dollar_amounts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3I5GZ5sMQv6"
      },
      "source": [
        "### Save Dollar Bars to Parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z8IFqUjSXbtA"
      },
      "outputs": [],
      "source": [
        "symbol = \"AMD\"\n",
        "df_dollar_bars.to_parquet(f\"/content/drive/MyDrive/dollar_bars_{symbol}.parquet\")\n",
        "df_daily_dollar_amounts.to_parquet(f\"/content/drive/MyDrive/daily_dollar_amounts_{symbol}.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save to MYSQL PythonAnywhere!"
      ],
      "metadata": {
        "id": "M5ziRoguTXf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sshtunnel pandas pymysql sqlalchemy\n",
        "\n",
        "import pandas as pd\n",
        "import pymysql\n",
        "from sqlalchemy import create_engine\n",
        "from sshtunnel import SSHTunnelForwarder\n",
        "from getpass import getpass\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def create_ssh_tunnel(ssh_host, ssh_username, ssh_password, mysql_host, mysql_port):\n",
        "    \"\"\"Create and return an SSH tunnel.\"\"\"\n",
        "    try:\n",
        "        tunnel = SSHTunnelForwarder(\n",
        "            (ssh_host, 22),\n",
        "            ssh_username=ssh_username,\n",
        "            ssh_password=ssh_password,\n",
        "            remote_bind_address=(mysql_host, mysql_port),\n",
        "            local_bind_address=('127.0.0.1', 3307)\n",
        "        )\n",
        "        tunnel.start()\n",
        "        logger.info(f\"SSH tunnel established to {ssh_host}. MySQL available at 127.0.0.1:{tunnel.local_bind_port}\")\n",
        "        return tunnel\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to create SSH tunnel: {e}\")\n",
        "        raise\n",
        "\n",
        "def create_sql_engine(mysql_username, mysql_password, db_name, tunnel):\n",
        "    \"\"\"Create and return SQLAlchemy engine.\"\"\"\n",
        "    try:\n",
        "        connection_string = f\"mysql+pymysql://{mysql_username}:{mysql_password}@127.0.0.1:{tunnel.local_bind_port}/{db_name}\"\n",
        "        engine = create_engine(connection_string, pool_pre_ping=True)\n",
        "        logger.info(\"SQLAlchemy engine created successfully\")\n",
        "        return engine\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to create SQL engine: {e}\")\n",
        "        raise\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    SSH_HOST = \"ssh.pythonanywhere.com\"\n",
        "    SSH_USERNAME = \"trademamba\"\n",
        "    MYSQL_HOST = \"trademamba.mysql.pythonanywhere-services.com\"  # Replace with your MySQL hostname\n",
        "    MYSQL_USERNAME = \"trademamba\"\n",
        "    MYSQL_PORT = 3306\n",
        "    DB_NAME = \"trademamba$default\"\n",
        "\n",
        "    # Get passwords securely\n",
        "    try:\n",
        "        ssh_password = getpass(\"Enter SSH password: \")\n",
        "        mysql_password = getpass(\"Enter MySQL password: \")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting passwords: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    tunnel = None\n",
        "    try:\n",
        "        # Create SSH tunnel\n",
        "        tunnel = create_ssh_tunnel(SSH_HOST, SSH_USERNAME, ssh_password, MYSQL_HOST, MYSQL_PORT)\n",
        "\n",
        "        # Create SQLAlchemy engine\n",
        "        engine = create_sql_engine(MYSQL_USERNAME, mysql_password, DB_NAME, tunnel)\n",
        "\n",
        "        # Test connection and write data\n",
        "        with engine.connect() as conn:\n",
        "            logger.info(\"Database connection successful\")\n",
        "            df_daily_dollar_amounts.reset_index().to_sql(\"daily_dollar_amounts\", engine, if_exists=\"replace\", index=False)\n",
        "            logger.info(\"Data successfully written to 'test' table\")\n",
        "            df_dollar_bars.to_sql(\"dollar_bars\", engine, if_exists=\"replace\",index=False)\n",
        "            logger.info(\"Data successfully written to 'test' table\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error: {e}\")\n",
        "        logger.info(\"\\nTroubleshooting tips:\")\n",
        "        logger.info(\"1. Verify MySQL hostname (e.g., trademba.mysql.pythonanywhere-services.com)\")\n",
        "        logger.info(\"2. Ensure SSH access is enabled in your PythonAnywhere account\")\n",
        "        logger.info(\"3. Check SSH and MySQL credentials\")\n",
        "        logger.info(\"4. Confirm sshtunnel is installed: pip install sshtunnel\")\n",
        "        logger.info(\"5. Verify port 22 (SSH) is not blocked by your network\")\n",
        "        logger.info(\"6. Contact PythonAnywhere support if MySQL server issues persist\")\n",
        "\n",
        "    finally:\n",
        "        if tunnel is not None and tunnel.is_active:\n",
        "            tunnel.stop()\n",
        "            logger.info(\"SSH tunnel closed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYrZXXMcTXbG",
        "outputId": "83037d71-9d1d-4a73-ac38-fa42e3fccaea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sshtunnel in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Requirement already satisfied: paramiko>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from sshtunnel) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.2)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.11/dist-packages (from paramiko>=2.7.2->sshtunnel) (4.3.0)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.11/dist-packages (from paramiko>=2.7.2->sshtunnel) (43.0.3)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.11/dist-packages (from paramiko>=2.7.2->sshtunnel) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.3->paramiko>=2.7.2->sshtunnel) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.7.2->sshtunnel) (2.22)\n",
            "Enter SSH password: ··········\n",
            "Enter MySQL password: ··········\n"
          ]
        }
      ]
    }
  ]
}